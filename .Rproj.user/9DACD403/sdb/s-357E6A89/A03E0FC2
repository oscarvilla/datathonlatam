{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Análisis exploratorio de datos2\"\noutput:\n  html_document: default\n  html_notebook: default\n  pdf_document: default\n---\n\n## 1. Obtener los datos\n\n### 1.1. Datos sobre educación:\n\nVamos a obtener los datos sobre acreditación por departamentos, años y nivel de educación teniendo en cuenta, a falta de la definición de una variable proxy en el [documento](http://www.mineducacion.gov.co/1759/w3-article-329021.html) del MEN, la acreditación en los diferentes niveles educativos nos da cuenta tanto de la diversidad de la propuesta educativa como de su calidad.\n\nDado que provienen de distintas tablas, es necesario verificar que los años coincidan, los departamentos y su escritura y los niveles educativos:\n\n```{r, get_data, cache=TRUE}\nsetwd(\"~/Documents/datathonlatam\") ## setting dir\nlibrary(readr)\narc <- list.files(\"./datasets/educacion_superior\", pattern = \".csv\") ## creating list files csv\n\nacreditacion <- read_csv(paste(\"./datasets/educacion_superior\", arc[1], sep = \"/\"))\nnames(acreditacion) <- c(\"departamento\", \"anio\", \n                         paste(\"acr\", gsub(\"tecnica profesional\", \"tecpro\", tolower(names(acreditacion)[3:8])), sep = \"_\") )\n```\n\n\nUna ves juntamos todos los datos, vamos a verificar que estén todos los departamentos, de cuáles años hay registros y los niveles educativos presentes:\n\n```{r, merging, cache=TRUE}\ndepartamentos <- sort(unique(acreditacion$departamento))\nprint(\"Tenemos los siguientes departamentos:\")\ndepartamentos\nprint(\"Para los años:\")\nsort(unique(acreditacion$anio))\nprint(\"Y para los niveles educativos:\")\ncolnames(acreditacion[3:8])\nsaveRDS(departamentos, \"./departamentosRDS\")\n```\n\n### 1.2. Obtener los datos sobre PIB:\n\n```{r, import_PIB, cache=TRUE}\ntotalpib <- data.frame() ## empty data frame to fill\nk <- 0 ## a counter for naming by department from departamentos var\ndepartamentos <- readRDS(\"./departamentosRDS\")\nlibrary(readxl) ## library needed to read xls\nfor(i in seq(from = 2, to = 66, by = 2)) { ## We'll read even sheets (by number, not by name)\n\npib <- read_excel(\"~/Documents/datathonlatam/datasets/Copia de PIB_Departamentos_2015provisional.xls\", \n                 sheet = i, skip = 5, range = \"A7:Q59\") ## read just a range of the sheet\npib <- pib[!is.na(pib[, 1]) & !is.na(pib[, 2]), c(1, 2:16)] ## delete NAs and keep 2010 to 2015\npib <- data.frame(t(pib)) ## transpose\nk <- k + 1 ## increase 'iterator' of departamentos names\npib$departamento <- departamentos[k] ## namig the departamento\npib$anio <- rownames(pib) ## anio as value not just as rowname\npib <- pib[c(2:nrow(pib)), c(48:49, 1:47)] ## erasing first row and reordering cols-vars\ntotalpib <- rbind(totalpib, pib) ## stacking results in one data frame\n}\n\nrm(pib) ## erase inecessary data frame\n\ntotalpib[, 3:ncol(totalpib)] <- apply(totalpib[, 3:ncol(totalpib)], 2, as.integer) ## data as numeric\n\nprint(\"los departamentos que quedan son:\")\nsort(unique(totalpib$departamento))\nprint(\"Y los años:\")\nsort(unique(totalpib$anio))\nlibrary(readr)\ndummy_names_PIB <- as.data.frame(read_csv(\"~/Documents/datathonlatam/dummy_names_PIB.csv\")[, c(1:2)])\nprint(\"Dado que no podemos conservar el nombre completo-descriptivo de cada variable, dejamos una tabla en el que se relacionan las convenciones y el nombre original\")\ndummy_names_PIB\n```\n\n\n### 1.3. Obtener los datos sobre proyecciones poblacionales del DANE según censo 2005:\n\n```{r, censo, cache=TRUE, message=FALSE}\nlibrary(readr)\ndane <- read_csv(\"./datasets/censo 2005/proyeccion poblacion DANE 2005.csv\")\n\ntotaldane <- data.frame()\nfor( i in 1:nrow(dane)){\n    temp <- data.frame(departamento = dane[i, 1], \n                                  anio = seq(1985, 2020), \n                                  proy = as.numeric(dane[i, 2:ncol(dane)]))\n    totaldane <- rbind(totaldane, temp)\n}\n\nrm(list = c(\"dane\", \"temp\"))\n\nprint(\"los departamentos que quedan son:\")\nsort(unique(totaldane$departamento))\nprint(\"Y los años:\")\nsort(unique(totaldane$anio))\n```\n\n### 1.4. Juntar todos los datos:\n\nAl tener para todos los sets de datos los mismos 33 departamentos (BOGOTA D.C.  se considera un departamento a parte de CUNDINAMARCA), sólo se vana conservar los datos de los años que coincidan en todos: para el caso, acreditación va a ser el límite de los demás. Y por tanto vamos a tener datos solamente entre 2010 y 2015.\n\n```{r, join_all, echo=FALSE, cache=TRUE}\ndf <- merge(merge(totaldane, totalpib), acreditacion)\ndf$departamento <- as.factor(df$departamento)\ndf$proy <- as.integer(df$proy)\nstr(df)\n```\n\n## 2. Análisis exploratorio de datos:\n\n### 2.1. Eliminando variables PIB redundantes:\n\nAhora que tenemos todos los datos juntos, lo primero que necesitamos es remover algunas variables del PIB que son suma de otras (X1 es la suma de X2 a X6, X7 es la suma de X8 a X11 ... Las que aparecen relacionadas en mayúscula son la suma de las isguientes en minúsculas, de acuerdo con la tabla presentada en el  apartado [1.2. Obtener los datos sobre PIB:]) ya que son redundantes.\n\n```{r, correlaciones, echo=FALSE, cache=TRUE}\ndf_limpio <- df[, -c(4, 10, 15, 18, 23, 26, 30, 36, 40, 48:50)]\ncorrelaciones <- cor(df_limpio[, c(2:ncol(df_limpio))])\n```\n\n### 2.2. Revisando correlaciones:\n\nUna vez retiradas podemos revisar las correlaciones entre todas las variables del PIB y las de acreditación en educación superior por nivel educativo; dejando por fuera los datos no numéricos: los nombres de los departamentos.\n\n```{r, corrplots, echo=FALSE, cache=TRUE}\nlibrary(corrplot)\ncorrplot(correlaciones[1:37, 38:43], order = \"original\", tl.cex = 0.6, tl.col = \"black\", type = \"lower\", diag = FALSE, title = \"Correlaciones entre todas las variables\")\n```\n\n```{r, echo=FALSE}\nlibrary(qgraph)\nqgraph(cor(correlaciones), shape=\"circle\", \n       posCol=\"darkblue\", negCol=\"darkred\", \n       layout=\"spring\", vsize=8, groups = list(Educación = c(38:43), PIB = c(1:37)))\n```\n\n```{r, reduct_correlations_spaces, echo=FALSE}\ncorrelate <- cor(df_limpio[, c(39:44)], df_limpio[, c(2:38)])\nlibrary(gplots)\nheatmap.2(correlate, dendrogram='none', Rowv=FALSE, Colv=FALSE,trace='none', margins = c(4, 13))\n\ncorrelate\n```\n\nLas correlaciones negativas son pocas y no muy altas: la correlación negativa más alta (más negativa) es `r min(correlaciones)`, mientras que postivas hay muchas, siendo la más alta `r max(correlaciones)`\n\nVeamos la dsitribución de las correlaciones:\n\n```{r, distribucion_corr, echo=FALSE, cache=TRUE}\nplot(density(correlaciones))\n```\n\nTenemos un grupo mayoritario de correlaciones cercanas al 1 y otro grupo de correlaciones cercanas al 0, y pocas negativas: preliminarmente puede decirse que a medida que crece el PIB en sus diferentes rubros, incrementa el número de programas de educación superior acreditados.\n\n## 3. Modelo generativo:\n\nNos referimos a un modelo generativo como aquel que permite a establecer la medida en que las variables independientes o conocidas determinan la variable dependiente o a predecir. En el presente caso, un modelo generativo permite predecir el número de programas acreditados para un nivel educativo a partir de los datos de PIB del departamento: si conocemos los datos de PIB del departamento podemos predecir o inferir el número de programas de cierto nivel académico acreditados en el departamento. \n\nLo importante de este tipo de modelo es que permite extraer la medida en que cada uno de los rubros del PIB contribuye al aumento o decremento del número de programas acreditados.\n\n### 3.1. Normalizando los datos\n\n```{r normaliz, echo=FALSE, cache=TRUE}\nlibrary(caret)\ntrans <- preProcess(df_limpio[, 4:38], method = c(\"BoxCox\", \"center\", \"scale\"))\ntrans\n```\n\nYa que conocemos los preprocesamientos calculados, sobre todo en lo que tiene que ver con los coeficientes BoxCox para mejorar las \n\n```{r}\nacr_tecpro <- df_limpio[, c(1:39)]\nmodel <- lm(acr_tecpro ~ ., data = acr_tecpro)\nsummary(model)\n```\n\n```{r}\nacr_tecpro <- df_limpio[, c(2:39)]\nmodel <- lm(acr_tecpro ~ ., data = acr_tecpro)\nsummary(model)\nplot(acr_tecpro$acr_tecpro, predict(model, newdata = data.frame(acr_tecpro[, -c(38)])))\nabline(coef = c(0, 1))\n```\n\n```{r, cache=TRUE}\nlibrary(caret)\nmodelrf <- train(acr_tecpro ~ ., data = acr_tecpro, method = \"rf\")\nplot(acr_tecpro$acr_tecpro, predict(modelrf, newdata = data.frame(acr_tecpro[, -c(38)])))\nabline(coef = c(0, 1))\n```\n\n",
    "created" : 1498403523621.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2665349087",
    "id" : "A03E0FC2",
    "lastKnownWriteTime" : 1498624716,
    "last_content_update" : 1498624716011,
    "path" : "~/Documents/datathonlatam/analisis_exploratorio2.Rmd",
    "project_path" : "analisis_exploratorio2.Rmd",
    "properties" : {
        "chunk_output_type" : "inline"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}